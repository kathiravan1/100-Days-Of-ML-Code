{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topicModeling1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HdN8bnrcxf8RfF5ZT6bgR6n8gu7DGZIC",
      "authorship_tag": "ABX9TyOgEU9Lf19eOmW2YfJu/e4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kathiravan1/100-Days-Of-ML-Code/blob/master/topicModeling1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "_5sP7TMs7-A0",
        "outputId": "7d2b5378-8fa6-485f-84fd-cfe2377c9c03"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "#vis = pyLDAvis.gensim_models.prepare(Ldamodel, doc_term_matrix, dictionary)\n",
        "#vis\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a5/15a0da6b0150b8b68610cc78af80364a80a9a4c8b6dd5ee549b8989d4b60/pyLDAvis-3.3.1.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 4.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/44/52/5cf7401456a461e4b481650dfb8279bc000f31a011d0918904f86e755947/funcy-1.16-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Collecting pandas>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Collecting numpy>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/42/560d269f604d3e186a57c21a363e77e199358d054884e61b73e405dd217c/numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 270kB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-cp37-none-any.whl size=136897 sha256=2b47883a7c03e067eaeae5868f65176c0109b47065d1e21dbe22718393126ab6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/9c/fc/c6e00689d35c82cf96a8adc70edfe7ba7904374fdac3240ac2\n",
            "Successfully built pyLDAvis\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: funcy, numpy, pandas, pyLDAvis\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "Successfully installed funcy-1.16 numpy-1.20.3 pandas-1.2.4 pyLDAvis-3.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3-oS-vaAMR2",
        "outputId": "4e00ebaf-75ca-45b7-c2ad-7212e90af877"
      },
      "source": [
        "# NLTK Stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use','a','about', 'above', 'across'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzYVoEoUAtMG"
      },
      "source": [
        "#data0 = pd.read_csv(\"/content/drive/MyDrive/dv/DataSet_DV.csv\")\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/dv/reddit_TM.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffVpZDo7M6g9"
      },
      "source": [
        "#data1=pd.read_csv(\"/content/drive/MyDrive/dvdata/reddit3attributes.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eKgLAiPy4iZ"
      },
      "source": [
        "#data0 = pd.read_csv(\"/content/drive/MyDrive/dvdata/Reddit1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_bCmHGVNJF9",
        "outputId": "5b434898-b407-44a4-aa8e-653ba82a6498"
      },
      "source": [
        "print(data.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            selftext\n",
            "0  God saying \"kas\" really doesn't roll off the t...\n",
            "1  [M,21] here.\\n\\nI have some social problem tha...\n",
            "2  After out first date...where we had a great ni...\n",
            "3  I have been with my girlfriend for about a yea...\n",
            "4  My friends, I spent much of this year speaking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUPKbSYy60c7",
        "outputId": "9a7e9acc-5e21-41d1-909c-e66f7a0dff58"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32933, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqJGz8frObQ7"
      },
      "source": [
        "#data.drop('subreddit',\n",
        "  #='columns', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJW0GHULQObP",
        "outputId": "c963092b-de74-4ff0-fb61-527af0421e37"
      },
      "source": [
        "print (data.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            selftext\n",
            "0  God saying \"kas\" really doesn't roll off the t...\n",
            "1  [M,21] here.\\n\\nI have some social problem tha...\n",
            "2  After out first date...where we had a great ni...\n",
            "3  I have been with my girlfriend for about a yea...\n",
            "4  My friends, I spent much of this year speaking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bewFeLj8QbPF",
        "outputId": "7fcc083d-f85e-44d8-e749-fae958f9ac71"
      },
      "source": [
        "df0=data.rename(columns={\"selftext\": \"Text\"})\n",
        "print (df0.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text\n",
            "0  God saying \"kas\" really doesn't roll off the t...\n",
            "1  [M,21] here.\\n\\nI have some social problem tha...\n",
            "2  After out first date...where we had a great ni...\n",
            "3  I have been with my girlfriend for about a yea...\n",
            "4  My friends, I spent much of this year speaking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s9r2Ys49juR",
        "outputId": "7684a802-2311-443f-e2e3-2ba78206ef85"
      },
      "source": [
        "df0.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32933, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfM6m-W5BgKZ"
      },
      "source": [
        "#print (data0.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uEuW5ovNR4W"
      },
      "source": [
        "#data = pd.concat([data0,df1], axis=0, ignore_index=True)\n",
        "#data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdRI8svLB7BT",
        "outputId": "750dd185-6138-45d4-e4b8-95375f3c125c"
      },
      "source": [
        "print (df0.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text\n",
            "0  God saying \"kas\" really doesn't roll off the t...\n",
            "1  [M,21] here.\\n\\nI have some social problem tha...\n",
            "2  After out first date...where we had a great ni...\n",
            "3  I have been with my girlfriend for about a yea...\n",
            "4  My friends, I spent much of this year speaking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O08F5a5SAz5f",
        "outputId": "8b13cca8-02ca-4c2d-8d90-781ede88668a"
      },
      "source": [
        "# Convert to list\n",
        "df = df0.Text.values.tolist()\n",
        "\n",
        "df = [re.sub('\\S*@\\S*\\s?', '',sent) for sent in df]\n",
        "\n",
        "# Remove new line characters\n",
        "df = [re.sub('\\s+', ' ', sent) for sent in df]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "df = [re.sub(\"\\'\", \"\", sent) for sent in df]\n",
        "\n",
        "print(df[:1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['God saying \"kas\" really doesnt roll off the tounge doesnt it?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLUc7CwRA7Ci"
      },
      "source": [
        "df = [re.sub(\"-\", \" \", sent) for sent in df]\n",
        "df = [re.sub(\":\", \"\", sent) for sent in df]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZd5P_ZGB0Vb"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "df_words = list(sent_to_words(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjJxgX2LCuBL",
        "outputId": "218c5441-2cbb-4f54-9668-068699037207"
      },
      "source": [
        "\n",
        "bigram = gensim.models.Phrases(df_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[df_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiW0LgqxCy_D"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhoTcsnPC0Xb"
      },
      "source": [
        "\n",
        "data_words_nostops = remove_stopwords(df_words)\n",
        "\n",
        "# Form Bigrams\n",
        "\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApZ8o0WBC-dK"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt_KSKyLDEMr",
        "outputId": "b3ac26e3-0b98-43b9-ab22-720a726054d5"
      },
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[11:12]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('say', 4),\n",
              "  ('be', 1),\n",
              "  ('feel', 1),\n",
              "  ('grow', 1),\n",
              "  ('know', 3),\n",
              "  ('normal', 2),\n",
              "  ('seem', 1),\n",
              "  ('want', 2),\n",
              "  ('ask', 1),\n",
              "  ('back', 2),\n",
              "  ('bed', 1),\n",
              "  ('could', 1),\n",
              "  ('date', 1),\n",
              "  ('hard', 1),\n",
              "  ('lot', 1),\n",
              "  ('make', 3),\n",
              "  ('mention', 1),\n",
              "  ('much', 1),\n",
              "  ('night', 1),\n",
              "  ('try', 1),\n",
              "  ('end', 1),\n",
              "  ('last', 1),\n",
              "  ('week', 1),\n",
              "  ('become', 1),\n",
              "  ('big', 1),\n",
              "  ('head', 1),\n",
              "  ('mind', 2),\n",
              "  ('nee', 1),\n",
              "  ('person', 1),\n",
              "  ('physical', 1),\n",
              "  ('reason', 1),\n",
              "  ('scared', 1),\n",
              "  ('small', 1),\n",
              "  ('take', 1),\n",
              "  ('therapist', 1),\n",
              "  ('well', 1),\n",
              "  ('already', 1),\n",
              "  ('figure', 1),\n",
              "  ('obviously', 1),\n",
              "  ('ruin', 1),\n",
              "  ('sometimes', 1),\n",
              "  ('bit', 3),\n",
              "  ('basically', 1),\n",
              "  ('issue', 1),\n",
              "  ('position', 2),\n",
              "  ('show', 1),\n",
              "  ('wear', 1),\n",
              "  ('alot', 1),\n",
              "  ('appreciate', 1),\n",
              "  ('appreciation', 1),\n",
              "  ('arm', 1),\n",
              "  ('awhile', 1),\n",
              "  ('behavior', 1),\n",
              "  ('bother', 1),\n",
              "  ('breaking', 1),\n",
              "  ('burn', 1),\n",
              "  ('caress', 1),\n",
              "  ('comfort', 2),\n",
              "  ('comfortable', 2),\n",
              "  ('communicate', 1),\n",
              "  ('compassionate', 1),\n",
              "  ('counsel', 1),\n",
              "  ('deep', 1),\n",
              "  ('discussion', 1),\n",
              "  ('floor', 1),\n",
              "  ('heart', 1),\n",
              "  ('hurting', 1),\n",
              "  ('imo', 1),\n",
              "  ('lay', 2),\n",
              "  ('lead', 1),\n",
              "  ('looking', 1),\n",
              "  ('mood', 1),\n",
              "  ('mother', 1),\n",
              "  ('negative', 1),\n",
              "  ('outweigh', 1),\n",
              "  ('possible', 1),\n",
              "  ('push', 1),\n",
              "  ('sacrifice', 3),\n",
              "  ('shoulder', 1),\n",
              "  ('simple', 1),\n",
              "  ('sleeve', 1),\n",
              "  ('statement', 2),\n",
              "  ('suggestion', 2),\n",
              "  ('thumb', 2),\n",
              "  ('tia', 1),\n",
              "  ('uncomfortable', 2),\n",
              "  ('woman', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gboEVxsPDIrk"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=5, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SRcTfeEDNxd",
        "outputId": "bd60b098-0b65-4d99-8840-34ec8f4f43df"
      },
      "source": [
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.043*\"be\" + 0.023*\"feel\" + 0.018*\"have\" + 0.014*\"anxiety\" + 0.014*\"people\" '\n",
            "  '+ 0.012*\"know\" + 0.012*\"make\" + 0.011*\"get\" + 0.011*\"think\" + 0.011*\"help\"'),\n",
            " (1,\n",
            "  '0.027*\"parent\" + 0.021*\"family\" + 0.021*\"child\" + 0.016*\"mom\" + '\n",
            "  '0.015*\"mother\" + 0.012*\"kid\" + 0.012*\"abuse\" + 0.012*\"old\" + '\n",
            "  '0.009*\"brother\" + 0.009*\"sister\"'),\n",
            " (2,\n",
            "  '0.023*\"want\" + 0.019*\"know\" + 0.019*\"friend\" + 0.017*\"would\" + 0.017*\"say\" '\n",
            "  '+ 0.017*\"go\" + 0.016*\"s\" + 0.016*\"time\" + 0.016*\"tell\" + 0.015*\"really\"'),\n",
            " (3,\n",
            "  '0.033*\"go\" + 0.022*\"get\" + 0.016*\"day\" + 0.012*\"say\" + 0.011*\"come\" + '\n",
            "  '0.011*\"night\" + 0.010*\"hour\" + 0.009*\"home\" + 0.009*\"take\" + 0.008*\"watch\"'),\n",
            " (4,\n",
            "  '0.034*\"job\" + 0.032*\"work\" + 0.022*\"live\" + 0.020*\"year\" + 0.019*\"would\" + '\n",
            "  '0.015*\"school\" + 0.014*\"move\" + 0.014*\"money\" + 0.013*\"pay\" + 0.013*\"want\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMQnLTADTZD",
        "outputId": "d7032200-8040-47e9-fd3d-26ee9a3ea808"
      },
      "source": [
        "\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus)) \n",
        "\n",
        "# Compute Coherence Score\n",
        "\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -6.998202422446057\n",
            "\n",
            "Coherence Score:  0.36153134558383837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I5dWXMCDcu8"
      },
      "source": [
        "# Visualize the topics\n",
        "\n",
        "#pyLDAvis.enable_notebook()\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "#vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itAnb1OkDkf9"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEiNuMEMDxFT"
      },
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=1, limit=6, step=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhN633HtD1UF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "852f7d26-4cf2-4c48-cffd-4da756860cfa"
      },
      "source": [
        "limit=3; start=1; step=1;\n",
        "x = range(start, limit, step)\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a2cafcb7509a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num Topics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coherence score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (5,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cib85aRED6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7032a56a-f720-4468-acd7-8c6cf7818afc"
      },
      "source": [
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Topics = 1  has Coherence Value of 0.281\n",
            "Num Topics = 2  has Coherence Value of 0.2773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTmkKg_xD-ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de15f4e-21de-495f-b36d-a0720d192055"
      },
      "source": [
        "# Select the model and print the topics\n",
        "\n",
        "optimal_model = model_list[3]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.018*\"be\" + 0.017*\"go\" + 0.017*\"want\" + 0.016*\"friend\" + 0.015*\"say\" + '\n",
            "  '0.015*\"know\" + 0.015*\"feel\" + 0.013*\"time\" + 0.013*\"really\" + 0.012*\"s\"'),\n",
            " (1,\n",
            "  '0.016*\"would\" + 0.013*\"say\" + 0.013*\"tell\" + 0.013*\"want\" + 0.012*\"year\" + '\n",
            "  '0.012*\"go\" + 0.011*\"know\" + 0.010*\"thing\" + 0.010*\"time\" + '\n",
            "  '0.010*\"relationship\"'),\n",
            " (2,\n",
            "  '0.016*\"go\" + 0.015*\"get\" + 0.013*\"be\" + 0.012*\"work\" + 0.010*\"would\" + '\n",
            "  '0.008*\"take\" + 0.008*\"time\" + 0.007*\"make\" + 0.007*\"know\" + 0.006*\"day\"'),\n",
            " (3,\n",
            "  '0.030*\"be\" + 0.016*\"feel\" + 0.012*\"get\" + 0.012*\"go\" + 0.012*\"have\" + '\n",
            "  '0.010*\"want\" + 0.010*\"know\" + 0.009*\"make\" + 0.009*\"really\" + 0.009*\"time\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2NuQQd4ED4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c40930-23ab-49d5-f48d-5609fb233cbc"
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
        "   \n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "   \n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # -- dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    \n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "    \n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=df)\n",
        "\n",
        "\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "\n",
        "print (df_dominant_topic.head(15))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Document_No  ...                                               Text\n",
            "0             0  ...  God saying \"kas\" really doesnt roll off the to...\n",
            "1             1  ...  [M,21] here. I have some social problem that I...\n",
            "2             2  ...  After out first date...where we had a great ni...\n",
            "3             3  ...  I have been with my girlfriend for about a yea...\n",
            "4             4  ...  My friends, I spent much of this year speaking...\n",
            "5             5  ...  You guys may be aware of this already but I ju...\n",
            "6             6  ...  So last night i broke my hand punching a chair...\n",
            "7             7  ...  Hey everyone, I just had broken up with my gir...\n",
            "8             8  ...  I happen to work with my partner in a restaura...\n",
            "9             9  ...  Just moved to new city ~6 months ago, first jo...\n",
            "10           10  ...  Around 7 oclock last night I was getting ready...\n",
            "11           11  ...  I have been dating a woman that is 30 for a fe...\n",
            "12           12  ...  It just happened like 2 hours ago and Im still...\n",
            "13           13  ...  I worked at a ramen shop, didnt get to know an...\n",
            "14           14  ...  This is like the one downside to cutting all o...\n",
            "\n",
            "[15 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO6i45JzEfrf"
      },
      "source": [
        "input = df_dominant_topic[['Dominant_Topic','Text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00lLO8Mg6Xe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97604e6-ca8d-465a-cbe3-45c5b3bb158a"
      },
      "source": [
        "input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32933, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoEGA7XJ9MKn"
      },
      "source": [
        "pip install pandas --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-a87K4accPE"
      },
      "source": [
        "pip install pandas==1.1.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQpEILlmEOj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd729072-b631-4952-8090-b8200fad57e9"
      },
      "source": [
        "print (input.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Dominant_Topic                                               Text\n",
            "0             0.0  God saying \"kas\" really doesnt roll off the to...\n",
            "1             3.0  [M,21] here. I have some social problem that I...\n",
            "2             0.0  After out first date...where we had a great ni...\n",
            "3             0.0  I have been with my girlfriend for about a yea...\n",
            "4             3.0  My friends, I spent much of this year speaking...\n",
            "5             3.0  You guys may be aware of this already but I ju...\n",
            "6             1.0  So last night i broke my hand punching a chair...\n",
            "7             2.0  Hey everyone, I just had broken up with my gir...\n",
            "8             1.0  I happen to work with my partner in a restaura...\n",
            "9             0.0  Just moved to new city ~6 months ago, first jo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imyvnd0cG5i7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "3b99fbbd-f486-4fe2-a526-28bafb7ed210"
      },
      "source": [
        "X1=input.to_csv('tmodel.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-385cfcdf5f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmodel.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3143\u001b[0m             \u001b[0mtabular\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m         \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0mHTML\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3145\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3146\u001b[0m         \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3147\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibwriters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mCompressionOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mFilePathOrBuffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'CompressionOptions' from 'pandas._typing' (/usr/local/lib/python3.7/dist-packages/pandas/_typing.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SngCRklX4vpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7e648d-67ca-4c68-c42f-8e739020cc6e"
      },
      "source": [
        "input=input.rename(columns={\"Dominant_Topic\": \"class\"})\n",
        "print (input.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   class                                               Text\n",
            "0    0.0  God saying \"kas\" really doesnt roll off the to...\n",
            "1    3.0  [M,21] here. I have some social problem that I...\n",
            "2    0.0  After out first date...where we had a great ni...\n",
            "3    0.0  I have been with my girlfriend for about a yea...\n",
            "4    3.0  My friends, I spent much of this year speaking...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zwiBoOQ4UD7"
      },
      "source": [
        "X, y = input['Text'], input['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "una-Gc9rPSb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11328e4e-a013-4819-e4cb-c9818512599e"
      },
      "source": [
        "documents = []\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "for sen in range(0, len(X)):\n",
        "    # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    \n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    \n",
        "    # Removing prefixed 'b'\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "    \n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    \n",
        "    documents.append(document)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QePoK_CS5fFn"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X = vectorizer.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIh5ha4Y5nYz"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDpllP3f5qJb"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "X = tfidfconverter.fit_transform(documents).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDVmYdsd5tDd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po4nM6jE5vl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767c95b6-4de9-4228-e5a4-3ea409a42da3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCj3U-bG5x88"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISAKYWz50Zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33347d95-2654-4118-9674-5e0c03400fc4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4842    8  102  320]\n",
            " [ 850  619   84  178]\n",
            " [ 535   91 1112  632]\n",
            " [ 637   51  155 2958]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.92      0.80      5272\n",
            "         1.0       0.80      0.36      0.50      1731\n",
            "         2.0       0.77      0.47      0.58      2370\n",
            "         3.0       0.72      0.78      0.75      3801\n",
            "\n",
            "    accuracy                           0.72     13174\n",
            "   macro avg       0.75      0.63      0.66     13174\n",
            "weighted avg       0.73      0.72      0.71     13174\n",
            "\n",
            "0.723470472142098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLQYY--T52kJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19051318-2cd8-47b6-b6fd-e23d7943f545"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rm72KzD56Qf"
      },
      "source": [
        "predictions = logmodel.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVGXkq3458U4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe951ce-4264-433b-bb2d-4b91c9350a4b"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.92      0.90      5272\n",
            "         1.0       0.86      0.73      0.79      1731\n",
            "         2.0       0.79      0.77      0.78      2370\n",
            "         3.0       0.85      0.86      0.85      3801\n",
            "\n",
            "    accuracy                           0.85     13174\n",
            "   macro avg       0.84      0.82      0.83     13174\n",
            "weighted avg       0.85      0.85      0.85     13174\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNJX3D1h5-m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b771594-4dc1-46a8-dcb3-abdfd14193e2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4860,   69,  152,  191],\n",
              "       [ 271, 1260,   94,  106],\n",
              "       [ 176,   68, 1827,  299],\n",
              "       [ 224,   62,  236, 3279]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3dX9Q316BZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a609d1-ed08-4852-d4a2-b96046264a83"
      },
      "source": [
        "result = logmodel.score(X_test, y_test)\n",
        "print(\"Accuracy: %.3f%%\" % (result*100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.213%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HADUwKG-6EN2"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "predictions = naive_bayes.predict(X_test)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYrUj2V6Mib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde24948-3d30-4085-c8c6-23da693ba44b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "print('Accuracy score:' , accuracy_score(y_test, predictions))\n",
        "#print('Precision score:' , precision_score(y_test, predictions))\n",
        "#print('Recall score: ', recall_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.7940640655837256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc-brYNE6PJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73ce8fc-0f71-463d-e6e4-bd132ad75434"
      },
      "source": [
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "from sklearn import svm\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(X_train, y_train)\n",
        "# predict the labels on validation dataset\n",
        "predictions = SVM.predict(X_test)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(y_test, predictions)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  84.05951115834219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NURRw2kBrcO"
      },
      "source": [
        "#Import knearest neighbors Classifier model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Create KNN Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "#Train the model using the training sets\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "predictions= knn.predict(X_test)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYLdJ7RFBsc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86dfd57-743f-44f8-ee09-9189abf9a97c"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.423257932290876\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}